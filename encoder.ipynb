{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb2f8053",
   "metadata": {},
   "source": [
    "# Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "185a8af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4249013",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelDataset(Dataset):\n",
    "    def __init__(self, csv_path, transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.mel_paths = self.df[\"mel_npy_path\"].tolist()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mel_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mel = np.load(self.mel_paths[idx])  # Shape: (n_mels, time)\n",
    "        mel = (mel - mel.min()) / (mel.max() - mel.min()) # Normalize to [0, 1]\n",
    "        mel = torch.tensor(mel, dtype=torch.float32).unsqueeze(0)  # (1, n_mels, time)\n",
    "        if self.transform:\n",
    "            mel = self.transform(mel)\n",
    "        return mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89b061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "            )  # Better than ReLU for autoencoders\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            ConvBlock(in_channels, out_channels),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "        self.conv = ConvBlock(out_channels * 2, out_channels)  # *2 for skip connection\n",
    "    \n",
    "    def forward(self, x, skip):\n",
    "        x = self.up(x)\n",
    "        # Handle potential size mismatches due to odd dimensions\n",
    "        if x.shape != skip.shape:\n",
    "            x = F.interpolate(x, size=skip.shape[2:], mode='bilinear', align_corners=True)\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72127b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=512):\n",
    "        super().__init__()\n",
    "        # Input: (1, 128, 861)\n",
    "        self.initial_conv = ConvBlock(1, 32)  # -> (32, 128, 861)\n",
    "        \n",
    "        self.down1 = DownBlock(32, 64)       # -> (64, 64, 430)\n",
    "        self.down2 = DownBlock(64, 128)      # -> (128, 32, 215)\n",
    "        self.down3 = DownBlock(128, 256)     # -> (256, 16, 107)\n",
    "        self.down4 = DownBlock(256, 512)     # -> (512, 8, 53)\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))  # -> (512, 1, 1)\n",
    "        self.proj = nn.Linear(512, embedding_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        skips = []\n",
    "        \n",
    "        x = self.initial_conv(x)\n",
    "        skips.append(x)\n",
    "        \n",
    "        x = self.down1(x)\n",
    "        skips.append(x)\n",
    "        \n",
    "        x = self.down2(x)\n",
    "        skips.append(x)\n",
    "        \n",
    "        x = self.down3(x)\n",
    "        skips.append(x)\n",
    "        \n",
    "        x = self.down4(x)\n",
    "        \n",
    "        x = self.pool(x)\n",
    "        x = x.flatten(1)\n",
    "        x = self.proj(x)\n",
    "        \n",
    "        return x, skips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f523eb8b-fc84-4c21-ad41-47ead28ad433",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelDecoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=512):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # Project latent vector back to feature map\n",
    "        self.fc = nn.Linear(embedding_dim, 512 * 8 * 8)\n",
    "        \n",
    "        # Upsampling blocks\n",
    "        self.up1 = UpBlock(512, 256)  # Input: 512, Output: 256\n",
    "        self.up2 = UpBlock(256, 128)   # Input: 256, Output: 128\n",
    "        self.up3 = UpBlock(128, 64)    # Input: 128, Output: 64\n",
    "        self.up4 = UpBlock(64, 32)     # Input: 64, Output: 32\n",
    "        \n",
    "        # Final convolution to get to original channels\n",
    "        self.final_conv = nn.Sequential(\n",
    "            nn.Conv2d(32, 1, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()  # Since mel-specs are normalized to [0,1]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, skips):\n",
    "        # Project latent vector\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, 512, 8, 8)\n",
    "        \n",
    "        # Reverse the skip connections for the decoder\n",
    "        skips = skips[::-1]\n",
    "        \n",
    "        # Upsampling with skip connections\n",
    "        x = self.up1(x, skips[3][:, :, :x.shape[2], :x.shape[3]])  # Match dimensions\n",
    "        x = self.up2(x, skips[2][:, :, :x.shape[2], :x.shape[3]])\n",
    "        x = self.up3(x, skips[1][:, :, :x.shape[2], :x.shape[3]])\n",
    "        x = self.up4(x, skips[0][:, :, :x.shape[2], :x.shape[3]])\n",
    "        \n",
    "        # Final convolution\n",
    "        x = self.final_conv(x)\n",
    "        \n",
    "        # Ensure output matches input dimensions\n",
    "        x = F.interpolate(x, size=(128, 861), mode='bilinear', align_corners=True)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b82d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelAutoencoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z, skips = self.encoder(x)\n",
    "        recon = self.decoder(z, skips)\n",
    "        return recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b73156e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_auto_encoder(model, train_loader, val_loader, epochs=200, checkpoint_dir='checkpoints/reference_encoder'):\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(\n",
    "        list(model.parameters()),\n",
    "        lr=1e-3, weight_decay=1e-4  # L2 regularization term\n",
    "    )\n",
    "\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # ----- Training -----\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for mel in train_loader:\n",
    "            mel = mel.to(device)  # [B, 1, M, T]\n",
    "            recon = model(mel)\n",
    "            loss = F.l1_loss(recon, mel) + 0.1 * F.mse_loss(recon, mel)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # ----- Validation -----\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for mel in val_loader:\n",
    "                mel = mel.to(device)\n",
    "                recon = model(mel)\n",
    "                loss = F.l1_loss(recon, mel)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch}, Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # ----- Save checkpoint -----\n",
    "        if epoch % 5 == 0:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pth')\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f\"Checkpoint saved to {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a885bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"Data/split_train_val/train_split.csv\")\n",
    "val_df = pd.read_csv(\"Data/split_train_val/val_split.csv\")\n",
    "\n",
    "train_df[\"mel_npy_path\"] = train_df[\"mel_npy_path\"].apply(lambda x: x.replace(\"\\\\\", \"/\"))\n",
    "val_df[\"mel_npy_path\"] = val_df[\"mel_npy_path\"].apply(lambda x: x.replace(\"\\\\\", \"/\"))\n",
    "\n",
    "train_dataset = MelDataset(csv_path=\"Data/split_train_val/train_split.csv\")\n",
    "val_dataset = MelDataset(csv_path=\"Data/split_train_val/val_split.csv\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "830c834f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given transposed=1, weight of size [256, 256, 4, 4], expected input[32, 192, 32, 64] to have 256 channels, but got 192 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m decoder = MelDecoder(embedding_dim=\u001b[32m512\u001b[39m, output_shape=(\u001b[32m128\u001b[39m, \u001b[32m861\u001b[39m)).to(device)\n\u001b[32m      5\u001b[39m autoencoder = MelAutoencoder(encoder=encoder, decoder=decoder).to(device)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mtrain_auto_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mautoencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mtrain_auto_encoder\u001b[39m\u001b[34m(model, train_loader, val_loader, epochs, checkpoint_dir)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mel \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[32m     15\u001b[39m     mel = mel.to(device)  \u001b[38;5;66;03m# [B, 1, M, T]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     recon = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     loss = F.l1_loss(recon, mel) + \u001b[32m0.1\u001b[39m * F.mse_loss(recon, mel)\n\u001b[32m     19\u001b[39m     optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mMelAutoencoder.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m      8\u001b[39m     z, skips, final_shape = \u001b[38;5;28mself\u001b[39m.encoder(x)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     recon = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskips\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m recon\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mMelDecoder.forward\u001b[39m\u001b[34m(self, x, skips, final_shape)\u001b[39m\n\u001b[32m     36\u001b[39m skip2_resized = F.interpolate(skip2, size=(x.shape[\u001b[32m2\u001b[39m], x.shape[\u001b[32m3\u001b[39m]), mode=\u001b[33m'\u001b[39m\u001b[33mbilinear\u001b[39m\u001b[33m'\u001b[39m, align_corners=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Concatenate with skip2 and pass through the next upsampling layer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mup3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip2_resized\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# -> (B, 256, 64, 128)\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Resize skip3 to match the spatial size of x before concatenation\u001b[39;00m\n\u001b[32m     42\u001b[39m skip3_resized = F.interpolate(skip3, size=(x.shape[\u001b[32m2\u001b[39m], x.shape[\u001b[32m3\u001b[39m]), mode=\u001b[33m'\u001b[39m\u001b[33mbilinear\u001b[39m\u001b[33m'\u001b[39m, align_corners=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:1162\u001b[39m, in \u001b[36mConvTranspose2d.forward\u001b[39m\u001b[34m(self, input, output_size)\u001b[39m\n\u001b[32m   1151\u001b[39m num_spatial_dims = \u001b[32m2\u001b[39m\n\u001b[32m   1152\u001b[39m output_padding = \u001b[38;5;28mself\u001b[39m._output_padding(\n\u001b[32m   1153\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1154\u001b[39m     output_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1159\u001b[39m     \u001b[38;5;28mself\u001b[39m.dilation,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   1160\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1162\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv_transpose2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_padding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Given transposed=1, weight of size [256, 256, 4, 4], expected input[32, 192, 32, 64] to have 256 channels, but got 192 channels instead"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "encoder = MelEncoder(embedding_dim=512).to(device)\n",
    "decoder = MelDecoder(embedding_dim=512, output_shape=(128, 861)).to(device)\n",
    "autoencoder = MelAutoencoder(encoder=encoder, decoder=decoder).to(device)\n",
    "\n",
    "train_auto_encoder(autoencoder, train_loader, val_loader, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2b17e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_first_10(autoencoder, dataloader, device, checkpoint_path = 'checkpoints/reference_encoder/checkpoint_epoch_20.pth'):\n",
    "    autoencoder.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    autoencoder.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            original = batch.to(device)\n",
    "            reconstructed = autoencoder(original)\n",
    "            break  # Only take the first batch\n",
    "\n",
    "    original = original.cpu()\n",
    "    reconstructed = reconstructed.cpu()\n",
    "\n",
    "    # Plot the first 10 samples\n",
    "    for i in range(10):\n",
    "        plt.figure(figsize=(10, 3))\n",
    "\n",
    "        # Original\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(original[i][0], aspect='auto', origin='lower', cmap='magma')\n",
    "        plt.title(f'Original #{i+1}')\n",
    "        plt.colorbar()\n",
    "\n",
    "        # Reconstructed\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(reconstructed[i][0], aspect='auto', origin='lower', cmap='magma')\n",
    "        plt.title(f'Reconstructed #{i+1}')\n",
    "        plt.colorbar()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2837054",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_first_10(autoencoder, val_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83662831-bade-44de-ae6a-1a837dfd7e23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
