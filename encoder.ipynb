{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb2f8053",
   "metadata": {},
   "source": [
    "# Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "185a8af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4249013",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelDataset(Dataset):\n",
    "    def __init__(self, csv_path, transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.mel_paths = self.df[\"mel_npy_path\"].tolist()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mel_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mel = np.load(self.mel_paths[idx])  # Shape: (n_mels, time)\n",
    "        mel = (mel - mel.min()) / (mel.max() - mel.min()) # Normalize to [0, 1]\n",
    "        mel = torch.tensor(mel, dtype=torch.float32).unsqueeze(0)  # (1, n_mels, time)\n",
    "        if self.transform:\n",
    "            mel = self.transform(mel)\n",
    "        return mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89b061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        self.shortcut = nn.Conv2d(in_channels, out_channels, 1, stride=2)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        x = self.conv(x)\n",
    "        x += residual\n",
    "        return self.activation(x)\n",
    "\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.upsample(x)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class MelAutoencoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, skips = self.encoder(x)\n",
    "        recon = self.decoder(z, skips)\n",
    "        return recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72127b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initial convolution with immediate downsampling\n",
    "        self.initial_conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=2, padding=2),  # /2\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Downsampling blocks\n",
    "        self.down1 = DownBlock(32, 64)    # /4\n",
    "        self.down2 = DownBlock(64, 128)   # /8\n",
    "        self.down3 = DownBlock(128, 256)  # /16\n",
    "        \n",
    "        # Final projection\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.proj = nn.Linear(256, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skips = []\n",
    "        \n",
    "        x = self.initial_conv(x)  # [B, 32, H/2, W/2]\n",
    "        skips.append(x)\n",
    "        \n",
    "        x = self.down1(x)        # [B, 64, H/4, W/4]\n",
    "        skips.append(x)\n",
    "        x = self.down2(x)        # [B, 128, H/8, W/8]\n",
    "        skips.append(x)\n",
    "        x = self.down3(x)        # [B, 256, H/16, W/16]\n",
    "        \n",
    "        x = self.pool(x)         # [B, 256, 1, 1]\n",
    "        x = x.flatten(1)         # [B, 256]\n",
    "        x = self.proj(x)         # [B, embedding_dim]\n",
    "        \n",
    "        return x, skips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f93a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelDecoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=256, output_shape=(128, 861)):\n",
    "        super().__init__()\n",
    "        self.output_shape = output_shape\n",
    "        \n",
    "        # Initial expansion\n",
    "        self.fc = nn.Linear(embedding_dim, 256 * 4 * 8)  # Matches encoder's final spatial dim\n",
    "        \n",
    "        # Upsampling blocks\n",
    "        self.up1 = UpBlock(256, 128)       # 4x8 -> 8x16\n",
    "        self.up2 = UpBlock(128 + 128, 64)  # 8x16 -> 16x32 (with skip)\n",
    "        self.up3 = UpBlock(64 + 64, 32)    # 16x32 -> 32x64 (with skip)\n",
    "        \n",
    "        # Final convolution\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(32 + 32, 16, 3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 1, 3, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, skips):\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, 256, 4, 8)  # [B, 256, 4, 8]\n",
    "        \n",
    "        # Reverse skip connections order to match decoder progression\n",
    "        skip1, skip2, skip3 = skips[2], skips[1], skips[0]\n",
    "        \n",
    "        x = self.up1(x)                         # [B, 128, 8, 16]\n",
    "        x = self.up2(torch.cat([x, skip3], dim=1))  # [B, 64, 16, 32]\n",
    "        x = self.up3(torch.cat([x, skip2], dim=1))  # [B, 32, 32, 64]\n",
    "        \n",
    "        # Final upsampling with initial skip\n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear')  # [B, 32, 64, 128]\n",
    "        x = self.final(torch.cat([x, skip1], dim=1))          # [B, 1, 64, 128]\n",
    "        x = F.interpolate(x, size=self.output_shape, mode='bilinear')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b82d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelAutoencoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, skips = self.encoder(x)  # Now unpack both embedding and skip connections\n",
    "        recon = self.decoder(z, skips)  # Pass both to decoder\n",
    "        return recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73156e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_auto_encoder(model, train_loader, val_loader, epochs=200, checkpoint_dir='checkpoints/reference_encoder'):\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(\n",
    "        list(model.parameters()),\n",
    "        lr=1e-3, weight_decay=1e-4  # L2 regularization term\n",
    "    )\n",
    "\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # ----- Training -----\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for mel in train_loader:\n",
    "            mel = mel.to(device)  # [B, 1, M, T]\n",
    "            recon = model(mel)\n",
    "            loss = F.l1_loss(recon, mel) + 0.1 * F.mse_loss(recon, mel)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # ----- Validation -----\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for mel in val_loader:\n",
    "                mel = mel.to(device)\n",
    "                recon = model(mel)\n",
    "                loss = F.l1_loss(recon, mel)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch}, Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # ----- Save checkpoint -----\n",
    "        if epoch % 5 == 0:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pth')\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f\"Checkpoint saved to {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a885bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"Data/split_train_val/train_split.csv\")\n",
    "val_df = pd.read_csv(\"Data/split_train_val/val_split.csv\")\n",
    "\n",
    "train_dataset = MelDataset(csv_path=\"Data/split_train_val/train_split.csv\")\n",
    "val_dataset = MelDataset(csv_path=\"Data/split_train_val/val_split.csv\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "encoder = MelEncoder(embedding_dim=512).to(device)\n",
    "decoder = MelDecoder(embedding_dim=512, output_shape=(128, 861)).to(device)\n",
    "autoencoder = MelAutoencoder(encoder=encoder, decoder=decoder).to(device)\n",
    "\n",
    "train_auto_encoder(autoencoder, train_loader, val_loader, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b17e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_first_10(autoencoder, dataloader, device, checkpoint_path = 'checkpoints/reference_encoder/checkpoint_epoch_20.pth'):\n",
    "    autoencoder.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    autoencoder.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            original = batch.to(device)\n",
    "            reconstructed = autoencoder(original)\n",
    "            break  # Only take the first batch\n",
    "\n",
    "    original = original.cpu()\n",
    "    reconstructed = reconstructed.cpu()\n",
    "\n",
    "    # Plot the first 10 samples\n",
    "    for i in range(10):\n",
    "        plt.figure(figsize=(10, 3))\n",
    "\n",
    "        # Original\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(original[i][0], aspect='auto', origin='lower', cmap='magma')\n",
    "        plt.title(f'Original #{i+1}')\n",
    "        plt.colorbar()\n",
    "\n",
    "        # Reconstructed\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(reconstructed[i][0], aspect='auto', origin='lower', cmap='magma')\n",
    "        plt.title(f'Reconstructed #{i+1}')\n",
    "        plt.colorbar()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2837054",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_first_10(autoencoder, val_loader, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
